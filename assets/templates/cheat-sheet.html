<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cheat Sheet: Enriching Word Vectors</title>
    <link rel="stylesheet" href="../assets/css/style.css">
</head>
<body>

    <header>
        <div class="container">
            <nav>
                <div class="menu-icon" id="menu-icon">
                    &#9776; <!-- Hamburger icon -->
                </div>
                <ul id="nav-links">
                    <li><a href="../index.html">Home</a></li>
                    <li><a href="../all-blogs.html">Blogs</a></li>
                    <li><a href="../all-projects.html">Projects</a></li>
                    <li><a href="../all-publications.html">Publications</a></li>
                    <li><a href="../assets/pdfs/Resume.pdf" target="_blank">Resume</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main>
        <section class="container">
            <h1 class="post-title">
                <a href="https://arxiv.org/pdf/1607.04606" target="_blank">
                    Cheat Sheet: Enriching Word Vectors with Subword Information
                </a>
            </h1>

            <h2>Key Points</h2>
            <ul>
                <li><strong>Paper:</strong> Enriching Word Vectors with Subword Information (2016)</li>
                <li><strong>Authors:</strong> [List Authors]</li>
                <li><strong>Concept:</strong> Introduces subword information to word vectors using n-grams.</li>
                <li><strong>Model:</strong> Extended Skipgram model using subword character n-grams.</li>
                <li><strong>Dataset:</strong> Wikipedia articles in multiple languages.</li>
                <li><strong>Performance:</strong> Achieves state-of-the-art results, especially in morphologically rich languages.</li>
            </ul>

            <h2>Equation</h2>
            <p style="text-align: center;">
                \[
                  s(w, c) = \sum_{{g \in G_w}} \mathbf{z}_g^\top \mathbf{v}_c
                \]
            </p>

            <h2>Main Contributions</h2>
            <ul>
                <li>Subword character n-grams improve word representation.</li>
                <li>Better generalization to rare or unseen words.</li>
                <li>Outperforms previous models, particularly in languages with complex morphology.</li>
            </ul>

            <h2>Abstract Summary</h2>
            <p>This paper proposes an extension to the Skipgram model where each word is represented as a bag of character n-grams. This method leads to state-of-the-art performance across various languages, especially in those with rich morphology.</p>

            <h2>Practical Insights</h2>
            <ul>
                <li>Incorporating subword information can significantly enhance word vector models.</li>
                <li>Performance trade-offs: 1.5x slowdown in comparison to the baseline due to complexity.</li>
                <li>Better generalization when data is limited or out-of-distribution.</li>
            </ul>

            <h2>Final Thoughts</h2>
            <p>This method was groundbreaking at the time but has since been surpassed by models that capture context better, such as Transformers.</p>
        </section>
    </main>
    
    <footer>
        <div class="container">
            <p class="copyright">&copy; 2024 Paul Jason Mello</p>
            <div class="social-links">
                <a href="https://x.com/pauljmello">Twitter</a> | 
                <a href="https://www.linkedin.com/in/pauljasonmello/">LinkedIn</a> | 
                <a href="https://github.com/pauljmello">GitHub</a> | 
                <a href="https://scholar.google.com/citations?user=AuGAXRwAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a>
            </div>
        </div>
    </footer>

</body>
</html>
